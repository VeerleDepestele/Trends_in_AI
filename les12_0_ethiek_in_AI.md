# Ethiek in AI

## Evolutie van AI

### 1. ANI - Artificial Narrow Intelligence (Smalle AI)

ANI verwijst naar AI-systemen die zijn ontworpen om één specifieke taak of een beperkt aantal gerelateerde taken uit te voeren. Dit type AI blinkt uit in een enkel domein, maar heeft geen algemene kennis of begrip buiten dat domein.

**Kenmerken**:

- Gespecialiseerd: Kan alleen taken uitvoeren waarvoor het specifiek is geprogrammeerd.
- Gebrek aan bewustzijn of zelflerend vermogen buiten het aangeleerde domein.

**Voorbeelden**:

- Spraakherkenning (zoals Siri of Google Assistant).
- Beeldherkenning (zoals gezichtsherkenning in foto's).
- Autonome voertuigen (die zich concentreren op navigatie en verkeersregels).

**Status**

ANI is het enige niveau van AI dat momenteel bestaat in de praktijk.

### 2. AGI - Artificial General Intelligence (Algemene AI)

AGI verwijst naar AI-systemen die menselijke cognitieve capaciteiten kunnen evenaren of repliceren. Het kan leren, redeneren, plannen en problemen oplossen in een breed scala van domeinen, net zoals een mens dat kan.

**Kenmerken**:

- Flexibel: Kan meerdere taken uitvoeren zonder expliciete programmering.
- Zelflerend vermogen: Leert nieuwe vaardigheden en past oude kennis toe in nieuwe situaties.
- Begrip van context: Begrijpt complexe en abstracte concepten.

**Status**

AGI bestaat nog niet en blijft een theoretisch concept, hoewel onderzoekers eraan werken. De ontwikkeling van AGI roept ethische vragen op over veiligheid, controle en impact op de mensheid.

### 3. ASI - Artificial Superintelligence (Superintelligente AI)

ASI verwijst naar AI die niet alleen menselijke intelligentie evenaart, maar deze ook ver overstijgt. Dit type AI zou in staat zijn om complexe problemen op te lossen die voor mensen onmogelijk zijn en zou op elk gebied superieur zijn aan menselijke capaciteiten.

**Kenmerken**:

- Overweldigende intelligentie: Begrijpt en overtreft menselijke intellectuele capaciteiten in elk domein.
- Potentieel autonoom: Kan zelf doelen en middelen bepalen om die doelen te bereiken.

**Mogelijke risico's**
Onvoorspelbare gevolgen voor de samenleving, afhankelijk van hoe het wordt ontworpen en gecontroleerd.

**Status**

ASI is volledig hypothetisch en wordt vaak besproken in filosofische, ethische en futuristische contexten.

## Vragen

### Vraag/bezorgdheid 1: Gaan we allemaal onze job verliezen aan AI?

- Welke types jobs gaan verloren door AI?
- Welke types jobs worden gecreëerd door AI?

- Reflectie over de invloed van het gebruik van AI ('cobots') op het kwalitatieve aspect van de jobinhoud:
  
  https://www.steunpuntwerk.be/publicaties/samenwerken-met-cobots-goed-nieuws-voor-de-kwaliteit-van-arbeid

- Reflectie over het nut van het aanleren/begrijpen van fundamentele concepten, bv. in computer wetenschappen, wanneer men snel en efficiënt geholpen is door generative AI:
  
  https://cacm.acm.org/news/the-impact-of-ai-on-computer-science-education/

### Vraag/bezorgdheid 2: Gaat AI ons volledig overnemen? - singulariteit

De technologische singulariteit—of simpelweg de singulariteit—is een hypothetisch toekomstig moment waarop technologische groei onbeheersbaar en onomkeerbaar wordt, met onvoorspelbare gevolgen voor de menselijke beschaving. (ref. https://en.wikipedia.org/wiki/Technological_singularity)

Het concept van de "singulariteit" in de context van kunstmatige intelligentie (AI) verwijst naar een hypothetisch moment in de toekomst waarop AI de menselijke intelligentie overtreft en in staat wordt tot zelfverbetering in een exponentieel tempo. Dit leidt tot ingrijpende en onvoorspelbare veranderingen in de samenleving, waarbij existentiële vragen worden opgeworpen over de rol, veiligheid en toekomst van de mensheid.

**Enkele ethische en filosofische overwegingen**

- **identiteit en bewustzijn**: Zou superintelligente AI bewustzijn bezitten, en hoe zou dat onze ethische verplichtingen ten opzichte van dergelijke systemen beïnvloeden?  
- **ongelijkheid**: Wie heeft de controle over of profiteert van de singulariteit? De concentratie van zulke macht zou sociale en economische ongelijkheden kunnen verergeren.  
- **overleving**: Kan de singulariteit leiden tot onbedoelde gevolgen, zoals de creatie van een AI-systeem dat zijn eigen doelen boven het voortbestaan van de mens stelt?  

Gedachte: "Reaching the singularity may be humanity's greatest and last accomplishment."

De vraag of kunstmatige intelligentie (AI) een existentieel risico vormt voor de mensheid is onderwerp van intens debat. Invloedrijke denkers en experts hebben uiteenlopende standpunten over de potentiële gevaren van AI.

Citaat van Stephen Hawking:
"“So we cannot know if we will be infinitely helped by AI, or ignored by it and side-lined, or conceivably destroyed by it. Unless we learn how to prepare for, and avoid, the potential risks, AI could be the worst event in the history of our civilization.”

Yann LeCun (meta) beschouwt de singulariteit als minder nabij en suggereert dat de zorgen overdreven zijn. Hij stelt dat AI-systemen hulpmiddelen zijn zonder inherente verlangens of intenties. Hij gelooft dat AI-systemen met zorgvuldig ontwerp en ethische overwegingen kunnen worden ontwikkeld om menselijke doelen te dienen en te versterken, zonder existentiële bedreigingen te vormen.

###  vraag/bezorgdheid 3: AI wordt ingezet om "verkeerde" dingen te doen

#### voorbeeld: manipulaties

Vb. Cambridge Analytica, 2016

Cambridge Analytica gebruikte facebookdata (zijn ze daar op een legale manier aangeraakt?) en andere data die ze ter beschikking hadden om de US burgers te overtuigen om voor Trump te stemmen bij de presidentsverkiezingen.

Ondanks het feit dat Trump op een bepaald moment in de peilingen achterliep op Hilary Clinton, heeft hij toch de verkiezingen gewonnen. Wat de echte impact van de acties van Cambridge Analitica was, is moeilijk in te schatten.

ref. https://www.jstor.org/stable/resrep45170.5?seq=3

Alhoewel niet officieel bewezen, werd Cambridge Analytica er ook van beschuldigd een belangrijke invloed gehad te hebben bij de stemming over de Brexit.

Dat soort manipulaties, zeer gerichte advertenties maken om mensen te overtuigen iets te doen, is één van de grote gevaren van AI. 

#### voorbeeld: the "entshitification of Tiktok" or "how platforms die"

https://www.wired.com/story/tiktok-platforms-cory-doctorow/

Idee: platformen worden zodanig overspoeld dat de interessante dingen niet meer terug te vinden zijn.

We spreken over klassieke censuur wanneer je verboden wordt iets te zeggen, waardoor je niet gehoord wordt.

Maar, wat wanneer je wel mag spreken, maar jouw verhaal zit tussen duizenden andere verhalen/dingen, waardoor je verdrongen wordt, waardoor je ook niet meer gehoord wordt, en je informatie niet meer verder geraakt?

Een heel onschuldig voorbeeld, zijn recepten die online staan. Veel van de recepten die je vindt, zijn automatisch gegenereerd.

De reden waarom mensen een heel verhaal rond een recept schrijven, is dat je op een recept geen copyright kan krijgen. Op teksten kan dat wel, vandaar dat mensen hun verhaal erbij zetten.
AI is goed in tekst genereren, dus zo een recepten site genereren is gemakkelijk. Er zitten dan wel fouten in. Het klinkt wel goed, maar het is niet juist.

Een voorbeeld van zo een site die recepten genereert, is "DishGen". Op deze site kunnen gebruikers een lijst met ingrediënten invoeren of een specifiek idee voor een recept geven. DishGen gebruikt AI om unieke recepten te genereren op basis van je input en biedt de mogelijkheid om recepten aan te passen als het eerste resultaat niet perfect is.

#### voorbeeld: "the Gospel"

https://www.pressreader.com/usa/the-guardian-usa/20231202/282548728035932

Het Israëlisch leger wou sneller doelwitten kunnen identificeren die ze zouden kunnen bombarderen. 
Met de standaardmethode die ze gebruikten, kroop er veel tijd in, waardoor ze een 50-tal doelwitten per jaar konden identificeren. Met het AI model dat ze ontwikkelden konden ze er (bij manier van spreken) 100 per dag identificeren. ("From 50 targets a year to 100 a day.")

#### voorbeeld: Tay.ai

Ze moest overkomen als een normale tienermeisje. Maar minder dan een dag na haar debuut op Twitter veranderde Microsoft’s chatbot – een AI-systeem genaamd “Tay.ai” – onverwachts in een Hitler-verheerlijkende, feminisme-bashende trol. Dus wat ging er mis? 

https://spectrum.ieee.org/in-2016-microsofts-racist-chatbot-revealed-the-dangers-of-online-conversation

### Vraag/bezorgdheid: wat is het alternatief voor 'slechte' AI?

Als je data niet fair is, gaat je AI ook nooit fair zijn.

Soms zijn problemen met AI minder duidelijk, minder expliciet, waardoor ze misschien nog gevaarlijker zijn.

Inleidend verhaal: 

In de jaren 50 bestond het Boston Symphony Orchestra vooral uit mannen. Maar, het is niet dat mannen inherent beter musziek kunnen spelen dan vrouwen.
Omdat men dat besefte, en die bias woul wegwerken, besloot men bij audities een doek te hangen en de mensen daarachter hun stuk te laten brengen. Op die manier zouden ze niet weten of er een man of een vrouw aan het spelen was, en dus een keuze kunnen maken, zonder beïnvloed te worden door de kennis van het geslacht van de persoon.
Wat bleek? Mannen en vrouwen dragen andere schoenen. Door het geluid dat de schoenen maakten op het podium, beseften de mensen die de selectie deden dat ze nog altijd wisten wie een man en wie een vrouw was. De oplossing bleek de mensen te vragen om zonder schoenen op het podium te staan.

Waarom dit voorbeeld? Om aan te tonen dat het niet altijd gemakkelijk is om te compenseren voor bias, wanneer die zich in de data bevindt. In het bovenstaande voorbeeld is het gelukt om 'de data' objectief te maken, dat lukt niet altijd.

Bv. Amazon maakte een AI om te helpen met het proces van het aanwerven van werknemers. 

Amazon is een zeer groot bedrijf, neemt heel veel werknemers in dienst per jaar. De aanwervingsprocedure is intens (duur): men schrijft een vacature uit, maakt een selectie uit de kandidaturen, voert een eerste gesprek, daarna volgen psychologische testen, wanneer iemand gekozen is, volgt de onboarding,...
Dus, iemand goed aanwerven is duur, iemand verkeerd aanwerven, is nog duurder (Je moet het hele proces herbeginnen).

Amazon heeft veel historische data, zowel van werknemers die ze aanwierven die goed bleken te zijn als van mensen waarvan ze niet tevreden waren. Daarom trainden ze er een model op. Verwacht werd dathet model het beter zou doen dan de mensen zelf, het model heeft immers meer informatie ter beschikking.

Wat bleek? Het AI model selecteerde personen op basis van het geslacht. (ref. explainability)

Als gevolg werd het model aangepast, zodat het geslacht niet meer als feature in het model werd gebracht, maar ook na het verwijderen van dat gegeven, kon het AI model nog ontdekken wat het geslacht van de persoon was (door andere kenmerken, interacties van features).
Er werd dus besloten het model offline te halen.

Je kan je de vraag stellen of het alternatief - de aanwerveringsprocedure terug doen zoals voorheen - beter is. Het gaan weer mensen zijn die mensen aanwerven. De reden dat de bias in de data zit, is omdat mensen op die manier werken.

Inherente bias uit data halen is niet gemakkelijk, niet altijd helemaal mogelijk.


### Vraag/bezorgdheid: Wat wil je? Wil je een zo performant modelijk model? Wil je dat het fair is?

Bedenking:
Wat wil je? Wil je dat bv. chatgpt zo goed mogelijk de teksten van het internet kan weergeven? Wil je dat het fair is?

Voorbeeld: "The nurse and the doctor were yelling at each other because she was late. Who was late?"

Bij LLMs, generative AI, kan je wenselijk gedrag (gedeeltelijk) aanleren a.d.h.v. RLHF (reïnforcement learning with human feedback).

Voorbeeld: de vdab website: https://www.vdab.be/
Analoog als bij het Amazon verhaal, zou je een model kunnen trainen, bv. op de CV's en welke jobs ermee gevonden werden.
Zo een model zou kunnen voorspellen dat mannen liever voltijds werken en vrouwen liever deeltijds.

Dat is een maatschappelijk probleem. Je zou die bias kunnen proberen wegwerken in je data alvorens je model te trainen.
Dus, dan houd je er geen rekening mee dat het historisch gezien zo was. Maar, dan is je model / voorspelling misschien minder efficiënt.

Werk je die maatschappelijke bias niet weg, en je toont alleen maar deeltijdse jobs aan vrouwen, dan gaan die misschien meer zo'n jobs aanvaarden en versterk je het nog.

Het idee is dat er geen juiste manier is om dingen te doen, er is altijd een keuze / een afweging.


### Vraag/bezorgdheid: What about sustainability?

Grote AI bedrijven gaan contracten aan om nucleaire energie te kunnen gebruiken.

Wat volgt zijn citaten en bedenkingen uit: ref. https://typeset.io/papers/sustainable-artificial-intelligence-systems-an-energy-34nge2ytet.
Ik geef het mee om een inschatting te krijgen van de energie-noden voor AI.

"De energieconsumptie voor AI gerelateerde toepassingen is x 300000 sinds 20212. 
Dit heeft een grote impact op het milieu: datacenters die AI ondersteunen, zijn verantwoordelijk voor 5-9% van de wereldwijde vraag naar elektriciteit en 2% van alle CO2-uitstoot."

De AI-gemeenschap erkent de noodzaak van energie-efficiënte AI. De focus verschuift van alleen prestaties naar energie-efficiëntie.
Onderzoekers verkennen strategieën om zowel prestaties als energie-efficiëntie te optimaliseren.

Elke fase van de ontwikkeling van AI-software, van algoritmeontwerp tot hardwarearchitectuur, wordt in overweging genomen.

Energieverbruik wordt niet alleen bekeken in het model zelf, maar ook in de infrastructuur en zelfs in de manier waarop gebruikers met AI omgaan.

Het draait om het optimaliseren van het hele systeem, niet alleen van de individuele componenten.

Strategieën om energieverbruik te verminderen:

- Het ontwikkelen van energiezuinige hardware.
- Het optimaliseren van modelarchitecturen voor een lager energieverbruik.
- Het optimaliseren van algoritmes om minder energie te verbruiken.
- Het ontwerpen van gebruikersinterfaces die energiegebruik minimaliseren.

Hierbij groeit het belang van gebruikerseducatie en verantwoorde AI-implementatie.







