{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2-B - Linear Quantization I: Get the Scale and Zero Point\n",
    "\n",
    "In this lesson, continue to learn about fundamentals of linear quantization, and implement your own Linear Quantizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to import all of the functions you have used before in the previous lesson(s) of `Linear Quantization I` to follow along with the video.\n",
    "\n",
    "- To access the `helper.py` file, you can click `File --> Open...`, on the top left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "height": 203
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from helper import linear_q_with_scale_and_zero_point, linear_dequantization, plot_quantization_errors\n",
    "\n",
    "### a dummy tensor to test the implementation\n",
    "test_tensor=torch.tensor(\n",
    "    [[191.6, -13.5, 728.6],\n",
    "     [92.14, 295.5,  -184],\n",
    "     [0,     684.6, 245.5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpKLMdCYvT_W"
   },
   "source": [
    "## Finding `Scale` and `Zero Point` for Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "q_min = torch.iinfo(torch.int8).min\n",
    "q_max = torch.iinfo(torch.int8).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-128"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# r_min = test_tensor.min()\n",
    "r_min = test_tensor.min().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-184.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "r_max = test_tensor.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728.5999755859375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scale = (r_max - r_min) / (q_max - q_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.578823433670343"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "zero_point = q_min - (r_min / scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-76.58645490333825"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "zero_point = int(round(zero_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-77"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, put all of this in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "height": 356,
    "id": "l1IRM2eazm7o"
   },
   "outputs": [],
   "source": [
    "def get_q_scale_and_zero_point(tensor, dtype=torch.int8):\n",
    "    \n",
    "    q_min, q_max = torch.iinfo(dtype).min, torch.iinfo(dtype).max\n",
    "    r_min, r_max = tensor.min().item(), tensor.max().item()\n",
    "\n",
    "    scale = (r_max - r_min) / (q_max - q_min)\n",
    "\n",
    "    zero_point = q_min - (r_min / scale)\n",
    "\n",
    "    # clip the zero_point to fall in [quantized_min, quantized_max]\n",
    "    if zero_point < q_min:\n",
    "        zero_point = q_min\n",
    "    elif zero_point > q_max:\n",
    "        zero_point = q_max\n",
    "    else:\n",
    "        # round and cast to int\n",
    "        zero_point = int(round(zero_point))\n",
    "    \n",
    "    return scale, zero_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test the implementation using the `test_tensor` defined earlier.\n",
    "```Python\n",
    "[[191.6, -13.5, 728.6],\n",
    " [92.14, 295.5,  -184],\n",
    " [0,     684.6, 245.5]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "height": 67,
    "id": "Us4-c4nnR2Ln"
   },
   "outputs": [],
   "source": [
    "new_scale, new_zero_point = get_q_scale_and_zero_point(\n",
    "    test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "9XA1_C8OUTVv",
    "outputId": "63eedcd1-c56b-444f-8812-baa19c5dc642"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.578823433670343"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "vC4QxI2jUUSe",
    "outputId": "5e8cde8e-6536-4db5-d1a8-b6660db4a755"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-77"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_zero_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization and Dequantization with Calculated `Scale` and `Zero Point`\n",
    "\n",
    "- Use the calculated `scale` and `zero_point` with the functions `linear_q_with_scale_and_zero_point` and `linear_dequantization`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "height": 67,
    "id": "C9MtUUysR6oH",
    "outputId": "4d6d769c-8db8-4f1c-c9d8-a3393e937c73"
   },
   "outputs": [],
   "source": [
    "quantized_tensor = linear_q_with_scale_and_zero_point(\n",
    "    test_tensor, new_scale, new_zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 67
   },
   "outputs": [],
   "source": [
    "dequantized_tensor = linear_dequantization(quantized_tensor,\n",
    "                                           new_scale, new_zero_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot to see how the Quantization Error looks like after using calculated `scale` and `zero_point`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 67
   },
   "outputs": [],
   "source": [
    "plot_quantization_errors(test_tensor, quantized_tensor, \n",
    "                         dequantized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 50
   },
   "outputs": [],
   "source": [
    "(dequantized_tensor-test_tensor).square().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original tensor and the dequantized tensor are very similar.\n",
    "The quantization error tensor looks also way much better (around 1.5 instead of 170 earlier, when considering random scale and zero point numbers.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYJxLMakItHX"
   },
   "source": [
    "### Put Everything Together: Your Own Linear Quantizer\n",
    "\n",
    "- Now, put everything togther to make your own Linear Quantizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear quantization function will only take a tensor and will return to you the quantized tensor, the scale and the zero point.\n",
    "In this function, we will use the two functions that we coded before.\n",
    "\n",
    "So, to get q_scales and the zero point, we just call the \"get_q_scales_and_zero_point\" function and we pass the tensor and also the d-type.\n",
    "\n",
    "Then after getting the scale and the zero point, we can perform the quantization of the tensor.\n",
    "\n",
    "We use the \"linear_q_scale_and_zero_point\" function we've coded before. We pass the tensor and the scale, the zero point, and the d-type.\n",
    "\n",
    "The \"linear_quantization\" function returns the quantized tensor, the scale and the zero point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 203,
    "id": "wWJWsvcYTGQc"
   },
   "outputs": [],
   "source": [
    "def linear_quantization(tensor, dtype=torch.int8):\n",
    "    # Given the tensor and desired quantized dtype, calculate the scale and zero point\n",
    "    scale, zero_point = get_q_scale_and_zero_point(tensor, \n",
    "                                                   dtype=dtype)\n",
    "    \n",
    "    # Given the tensor, scale, zero point and desired quantized dtype, calculate the quantized tensor\n",
    "    quantized_tensor = linear_q_with_scale_and_zero_point(tensor,\n",
    "                                                          scale, \n",
    "                                                          zero_point, \n",
    "                                                          dtype=dtype)\n",
    "    \n",
    "    return quantized_tensor, scale , zero_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qC0X9ux6JEmi"
   },
   "source": [
    "- Test your implementation on a random matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "height": 30,
    "id": "QxWC2JPbIkS7",
    "outputId": "b583d611-c00c-4ac7-b2ae-10e83f2d295a"
   },
   "outputs": [],
   "source": [
    "r_tensor = torch.randn((4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7373, -0.5947,  1.1786,  0.6481],\n",
       "        [ 1.0361, -0.2536, -1.5978,  1.3848],\n",
       "        [-0.8686, -0.7569, -0.3600, -0.8526],\n",
       "        [ 0.0768,  1.4115, -0.9894,  0.3041]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 50
   },
   "outputs": [],
   "source": [
    "quantized_tensor, scale, zero_point = linear_quantization(r_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "quantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 67
   },
   "outputs": [],
   "source": [
    "dequantized_tensor = linear_dequantization(quantized_tensor,\n",
    "                                           scale, zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 67
   },
   "outputs": [],
   "source": [
    "plot_quantization_errors(r_tensor, quantized_tensor,\n",
    "                         dequantized_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 50
   },
   "outputs": [],
   "source": [
    "(dequantized_tensor-r_tensor).square().mean()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "kd9Q2SD0MJGw",
    "E1palk4uRQX9",
    "oAexFpXiX1PW",
    "ChnEqFPYMn3p",
    "MFx2m7RmzRd5",
    "LbPjb9OOi0Xp",
    "6WopWDYWQr7X",
    "LYfTqh_VMTzT",
    "4YZP-9XTNkur",
    "dpKLMdCYvT_W",
    "2hoC5tcJznoI",
    "S68UGldKRnJc",
    "Y4Qfalu9vtHv",
    "WJN9IfVLTFNd",
    "qC0X9ux6JEmi",
    "AkwpMs-C5ccj",
    "EDpd5Te632KY",
    "JA1-rcLz4t4D",
    "kROAEGfdDsau",
    "oo4BCLpsDw3t",
    "h2gK-eALFc8U",
    "yDin7Rm6Dzqu",
    "X6J9ZiyHWzHa",
    "qUw1gQUu5yIe",
    "vGll7vBT6BGI",
    "Cl3AUuDuAH5w",
    "8NS1TnQt6E6v",
    "vcRy85lACotg"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Trends_in_AI_development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
