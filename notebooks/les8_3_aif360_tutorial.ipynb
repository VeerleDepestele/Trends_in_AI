{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45eb89a0-6b83-44e0-aed7-ed02d14ebf71",
   "metadata": {},
   "source": [
    "# AIF360 - total_credit_scoring\n",
    "\n",
    "Here the following notebook is replicated.\n",
    "There are some adaptations in order to get (easy) access to the data.\n",
    "\n",
    "ref. https://github.com/Trusted-AI/AIF360/blob/main/examples/tutorial_credit_scoring.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0650e2f9-ebe8-4148-970e-9d617d1b76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the aif360 package\n",
    "\n",
    "!pip install -qU aif360\n",
    "!pip install -qU 'aif360[Reductions]'\n",
    "!pip install -qU 'aif360[inFairness]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9be8188-8169-4f8a-a8a4-9d77c860c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all necessary packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "\n",
    "# Code from the original dataset, it is replaced by the code in the cell below.\n",
    "# This: from aif360.datasets import GermanDataset -> replace by using the class \"MyGermanDataset\" to which\n",
    "# you add the path where you've stored the \"german.data\" file.\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import warnings                   # to deal with warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b8869-6333-428c-9d98-1f4d4629988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're working with Google Colab and the data is located in your Google Drive:\n",
    "\n",
    "# Mount your google drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# The path is something like: \"/content/drive/MyDrive/Colab Data/german.data\", for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c4059b-63f7-40e1-b434-a16e36f3fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of using the GermanDataset class, which loads the \"german.data\" file from a location relative to the file you're running,\n",
    "# you can save the \"german.data\" file in a location of your choice and load it from there.\n",
    "\n",
    "# Therefore, use the class \"MyGermanDataset\" defined in this cell, passing it the \"path\" of the file, instead of the predefined\n",
    "# Germandataset from aif360.datasets.\n",
    "\n",
    "# Download the \"german.data\" file from:\n",
    "# https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data\n",
    "\n",
    "default_mappings = {\n",
    "    'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
    "    'protected_attribute_maps': [{1.0: 'Male', 0.0: 'Female'},\n",
    "                                 {1.0: 'Old', 0.0: 'Young'}],\n",
    "}\n",
    "def default_preprocessing(df):\n",
    "    \"\"\"Adds a derived sex attribute based on personal_status.\"\"\"\n",
    "    # TODO: ignores the value of privileged_classes for 'sex'\n",
    "    status_map = {'A91': 'male', 'A93': 'male', 'A94': 'male',\n",
    "                  'A92': 'female', 'A95': 'female'}\n",
    "    df['sex'] = df['personal_status'].replace(status_map)\n",
    "\n",
    "    return df\n",
    "\n",
    "class MyGermanDataset(StandardDataset):\n",
    "    \"\"\"German credit Dataset.\n",
    "\n",
    "    See :file:`aif360/data/raw/german/README.md`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, label_name='credit', favorable_classes=[1],\n",
    "                 protected_attribute_names=['sex', 'age'],\n",
    "                 privileged_classes=[['male'], lambda x: x > 25],\n",
    "                 instance_weights_name=None,\n",
    "                 categorical_features=['status', 'credit_history', 'purpose',\n",
    "                     'savings', 'employment', 'other_debtors', 'property',\n",
    "                     'installment_plans', 'housing', 'skill_level', 'telephone',\n",
    "                     'foreign_worker'],\n",
    "                 features_to_keep=[], features_to_drop=['personal_status'],\n",
    "                 na_values=[], custom_preprocessing=default_preprocessing,\n",
    "                 metadata=default_mappings,\n",
    "                 path = None):\n",
    "        \"\"\"See :obj:`StandardDataset` for a description of the arguments.\n",
    "\n",
    "        By default, this code converts the 'age' attribute to a binary value\n",
    "        where privileged is `age > 25` and unprivileged is `age <= 25` as\n",
    "        proposed by Kamiran and Calders [1]_.\n",
    "\n",
    "        References:\n",
    "            .. [1] F. Kamiran and T. Calders, \"Classifying without\n",
    "               discriminating,\" 2nd International Conference on Computer,\n",
    "               Control and Communication, 2009.\n",
    "\n",
    "        Examples:\n",
    "            In some cases, it may be useful to keep track of a mapping from\n",
    "            `float -> str` for protected attributes and/or labels. If our use\n",
    "            case differs from the default, we can modify the mapping stored in\n",
    "            `metadata`:\n",
    "\n",
    "            >>> label_map = {1.0: 'Good Credit', 0.0: 'Bad Credit'}\n",
    "            >>> protected_attribute_maps = [{1.0: 'Male', 0.0: 'Female'}]\n",
    "            >>> gd = GermanDataset(protected_attribute_names=['sex'],\n",
    "            ... privileged_classes=[['male']], metadata={'label_map': label_map,\n",
    "            ... 'protected_attribute_maps': protected_attribute_maps})\n",
    "\n",
    "            Now this information will stay attached to the dataset and can be\n",
    "            used for more descriptive visualizations.\n",
    "        \"\"\"\n",
    "\n",
    "        #filepath = os.path.join(os.path.dirname(os.path.abspath(__file__)),\n",
    "        #                        '..', 'data', 'raw', 'german', 'german.data')\n",
    "        filepath = path\n",
    "        # as given by german.doc\n",
    "        column_names = ['status', 'month', 'credit_history',\n",
    "            'purpose', 'credit_amount', 'savings', 'employment',\n",
    "            'investment_as_income_percentage', 'personal_status',\n",
    "            'other_debtors', 'residence_since', 'property', 'age',\n",
    "            'installment_plans', 'housing', 'number_of_credits',\n",
    "            'skill_level', 'people_liable_for', 'telephone',\n",
    "            'foreign_worker', 'credit']\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, sep=' ', header=None, names=column_names,\n",
    "                             na_values=na_values)\n",
    "        except IOError as err:\n",
    "            print(\"IOError: {}\".format(err))\n",
    "            print(\"To use this class, please download the following files:\")\n",
    "            print(\"\\n\\thttps://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\")\n",
    "            print(\"\\thttps://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\")\n",
    "            print(\"\\nand place them, as-is, in the folder:\")\n",
    "            print(\"\\n\\t{}\\n\".format(os.path.abspath(os.path.join(\n",
    "                os.path.abspath(__file__), '..', '..', 'data', 'raw', 'german'))))\n",
    "            import sys\n",
    "            sys.exit(1)\n",
    "\n",
    "        super(MyGermanDataset, self).__init__(df=df, label_name=label_name,\n",
    "            favorable_classes=favorable_classes,\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "            privileged_classes=privileged_classes,\n",
    "            instance_weights_name=instance_weights_name,\n",
    "            categorical_features=categorical_features,\n",
    "            features_to_keep=features_to_keep,\n",
    "            features_to_drop=features_to_drop, na_values=na_values,\n",
    "            custom_preprocessing=custom_preprocessing, metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb537b8-e80a-4c26-9d6e-8ecdda079c8f",
   "metadata": {},
   "source": [
    "## Step 2 Load dataset, specifying protected attribute, and split dataset into train and test\n",
    "\n",
    "In Step 2 we load the initial dataset, setting the protected attribute to be age. We then split the original dataset into training and testing datasets. Although we will use only the training dataset in this tutorial, a normal workflow would also use a test dataset for assessing the efficacy (accuracy, fairness, etc.) during the development of a machine learning model. \n",
    "\n",
    "Finally, we set two variables (to be used in Step 3) for the privileged (1) and unprivileged (0) values for the age attribute. These are key inputs for detecting and mitigating bias, which will be Step 3 and Step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fffdef4-21a6-4d18-9b5d-a8fa50754ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.MyGermanDataset'>\n",
      "['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_de_dummy_code_df', '_parse_feature_names', 'align_datasets', 'convert_to_dataframe', 'copy', 'export_dataset', 'favorable_label', 'feature_names', 'features', 'ignore_fields', 'import_dataset', 'instance_names', 'instance_weights', 'label_names', 'labels', 'metadata', 'privileged_protected_attributes', 'protected_attribute_names', 'protected_attributes', 'scores', 'split', 'subset', 'temporarily_ignore', 'unfavorable_label', 'unprivileged_protected_attributes', 'validate_dataset']\n",
      "   month  credit_amount  investment_as_income_percentage  residence_since  \\\n",
      "0    6.0         1169.0                              4.0              4.0   \n",
      "1   48.0         5951.0                              2.0              2.0   \n",
      "2   12.0         2096.0                              2.0              3.0   \n",
      "3   42.0         7882.0                              2.0              4.0   \n",
      "4   24.0         4870.0                              3.0              4.0   \n",
      "\n",
      "   age  number_of_credits  people_liable_for  status=A11  status=A12  \\\n",
      "0  1.0                2.0                1.0         1.0         0.0   \n",
      "1  0.0                1.0                1.0         0.0         1.0   \n",
      "2  1.0                1.0                2.0         0.0         0.0   \n",
      "3  1.0                1.0                2.0         1.0         0.0   \n",
      "4  1.0                2.0                2.0         1.0         0.0   \n",
      "\n",
      "   status=A13  ...  housing=A153  skill_level=A171  skill_level=A172  \\\n",
      "0         0.0  ...           0.0               0.0               0.0   \n",
      "1         0.0  ...           0.0               0.0               0.0   \n",
      "2         0.0  ...           0.0               0.0               1.0   \n",
      "3         0.0  ...           1.0               0.0               0.0   \n",
      "4         0.0  ...           1.0               0.0               0.0   \n",
      "\n",
      "   skill_level=A173  skill_level=A174  telephone=A191  telephone=A192  \\\n",
      "0               1.0               0.0             0.0             1.0   \n",
      "1               1.0               0.0             1.0             0.0   \n",
      "2               0.0               0.0             1.0             0.0   \n",
      "3               1.0               0.0             1.0             0.0   \n",
      "4               1.0               0.0             1.0             0.0   \n",
      "\n",
      "   foreign_worker=A201  foreign_worker=A202  credit  \n",
      "0                  1.0                  0.0     1.0  \n",
      "1                  1.0                  0.0     2.0  \n",
      "2                  1.0                  0.0     1.0  \n",
      "3                  1.0                  0.0     1.0  \n",
      "4                  1.0                  0.0     2.0  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset_orig = MyGermanDataset(\n",
    "    protected_attribute_names=['age'],           # this dataset also contains protected\n",
    "                                                 # attribute for \"sex\" which we do not\n",
    "                                                 # consider in this evaluation\n",
    "    privileged_classes=[lambda x: x >= 25],      # age >=25 is considered privileged\n",
    "    features_to_drop=['personal_status', 'sex'], # ignore sex-related attributes\n",
    "    path = \"replace_this_by_your_(relative)_file_path\"      # I've put the file in \"./data/german.data\"\n",
    ")\n",
    "\n",
    "\n",
    "print(type(dataset_orig))\n",
    "print(dir(dataset_orig))\n",
    "\n",
    "a = dataset_orig.convert_to_dataframe()\n",
    "print(a[0].head())\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb26562f-a118-4d62-ac81-1d42e31c59aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(set(dataset_orig.instance_weights))\n",
    "for el in set(dataset_orig.instance_weights):\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a3542-fde5-4283-b097-90a26c345b72",
   "metadata": {},
   "source": [
    "## Step 3 Compute fairness metric on original training dataset\n",
    "\n",
    "Now that we've identified the protected attribute 'age' and defined privileged and unprivileged values, we can use aif360 to detect **bias in the dataset**. \n",
    "\n",
    "One simple test is to compare the percentage of favorable results for the privileged and unprivileged groups, subtracting the former percentage from the latter. \n",
    "\n",
    "A negative value indicates less favorable outcomes for the unprivileged groups. \n",
    "\n",
    "This is implemented in the method called mean_difference on the BinaryLabelDatasetMetric class. \n",
    "\n",
    "The code below performs this check and displays the output, showing that the difference is -0.169905."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ed2d152-536e-43f7-aa1d-a97c8997acfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.129916\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c89e93-2133-4d73-83f5-543beafcbc03",
   "metadata": {},
   "source": [
    "## Step 4 Mitigate bias by transforming the original dataset\n",
    "\n",
    "The previous step showed that the privileged group was getting 13% more positive outcomes in the training dataset. \n",
    "\n",
    "Since this is not desirable, we are going to try to mitigate this bias in the training dataset. As stated above, this is called **pre-processing mitigation** because it happens before the creation of the model.\n",
    "\n",
    "AI Fairness 360 implements several pre-processing mitigation algorithms. We will choose the **Reweighing algorithm**, which is implemented in the Reweighing class in the aif360.algorithms.preprocessing package. This algorithm will transform the dataset to have more equity in positive outcomes on the protected attribute for the privileged and unprivileged groups.\n",
    "\n",
    "We then call the fit and transform methods to perform the transformation, producing a newly transformed training dataset (dataset_transf_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "589fa5e4-93eb-44e2-804e-ddb1ce395ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf_train = RW.fit_transform(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88787b86-0008-4520-902a-25591b854ce7",
   "metadata": {},
   "source": [
    "## Step 5 Compute fairness metric on transformed dataset\n",
    "\n",
    "Now that we have a transformed dataset, we can check how effective it was in removing bias by using the same metric we used for the original training dataset in Step 3. \n",
    "\n",
    "Once again, we use the function mean_difference in the BinaryLabelDatasetMetric class. \n",
    "\n",
    "We see the mitigation step was very effective, the difference in mean outcomes is now 0.0. So we went from a 13% advantage for the privileged group to equality in terms of mean outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b15913d7-7105-43f1-87d3-a5d6978f44bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
     ]
    }
   ],
   "source": [
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                               unprivileged_groups=unprivileged_groups,\n",
    "                                               privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
